# -*- coding: utf-8 -*-
import re
import os
import cve

from database import *
from bs4 import BeautifulSoup
from bs4.element import NavigableString

ICSCERT_URL = "https://ics-cert.us-cert.gov"
ICS_CERT_ADVISORIES_URL = ICSCERT_URL + "/advisories/{name}"


class ICSAHeader:
    def __init__(self, cvss, attention, vendor, equipment, vulnerability):
        self.cvss = cvss
        self.attention = attention
        self.vendor = vendor
        self.equipment = equipment
        self.vulnerability = vulnerability


class Icscert(cve.CVEDatabase):
    def __init__(self):
        super().__init__("icscert")
        self.headers = None
        self.last_updated = None

    def _append(self, tag_list, pattern, start_index=0):
        result = ''
        select = str(tag_list[start_index])
        index = 0
        try:
            while pattern.search(select) is None:
                result += str(tag_list[index])
                index = index + 1
                select = str(tag_list[index])
        except IndexError as e:
            return result
        return result

    def encap(self, icsa):
        cvss = None
        attact = None
        vender = None
        equip = None
        vuln = None
        pvuln = re.compile(r"Vulnerabilit(y|ies)(:?|. +?)|.*VULNERABILITY OVERVIEW|IMPACT|^.[A-Z]+$")
        update_filter = re.compile(r"-+ [a-zA-Z]{3,5} [A-Z].+[0-9]{1,2} of [0-9]{1,2} -+|The following .* are affected(:?)")

        if type(icsa[0]) != NavigableString:
            icsaHeader = ICSAHeader(icsa[0].get_text(), icsa[1].get_text(), icsa[2].get_text(), icsa[3].get_text(),
                                    icsa[4].get_text())
        else:
            for index, tag in enumerate(icsa):
                if vuln is not None:
                    break
                result = str(tag)
                if cvss is None:
                    cvss = self.find_from(re.compile(r"CVSS v[0-3] [0-9]{1,2}.[0-9]"), icsa)
                    #cvss = update_filter.sub('', self._append(icsa[index + 1:], re.compile(r"(ATTENTION(:?)|Vendor(:?)|"
                    #                                                                      r".*UPDATE INFORMATION)")))
                if "ATTENTION" in result or "OVERVIEW" in result:
                    attact = update_filter.sub('', self._append(icsa[index + 1:], re.compile(r"Vendor(:?)|AFFECTED PRODUCTS")))

                elif "Vendor" in result or "AFFECTED PRODUCTS" in result:
                    vender = update_filter.sub('', self._append(icsa[index + 1:], re.compile(r"Equipment(:?)|^[A-Z]+$")))

                elif re.compile(r"Equipment(:?)|.*AFFECTED PRODUCTS").search(result) is not None:
                    equip = update_filter.sub('', self._append(icsa[index + 1:], pvuln))

                elif pvuln.search(result) is not None:
                    vuln = update_filter.sub('', self._append(icsa[index + 1:], re.compile(r"RISK EVALUATION|.*UPDATE INFORMATION(:?)")))
            icsaHeader = ICSAHeader(cvss, attact, vender, equip, vuln)
        if icsaHeader.vendor is None or icsaHeader.equipment is None:
            print("FAILED, IT NEEDS TO CHECK ELEMENTS: %s" % (icsaHeader.__str__()))
        else:
            print("SUCCESS: %s" % (icsaHeader.__str__()))

    def find_from(self, pattern, list_tag, pos=0):
        for l in list_tag:
            n = pattern.search(str(l))
            if n is not None:
                return n.string
        return None

    def scan(self, icsa_id):
        url = ICS_CERT_ADVISORIES_URL.format(name=icsa_id)
        util.downloadfrom(url, icsa_id + ".html", output_log=False)
        with open(icsa_id + '.html', encoding="UTF8") as fp:
            soup = BeautifulSoup(fp, 'html.parser')
        data = []
        for element in soup.find_all("", {"id": "ncas-content"}):
            tag = element.find("", {"class": "field-item"})
            if tag is not None:
                index_list = []
                for header in tag.find_all('h2'):
                    try:
                        index = tag.contents.index(header)
                        if not index == -1:
                            index_list.append((index, header))
                    except ValueError as e:
                        # That is not h2 header with overview summary, So It needs to scarch the element manually.
                        data.append(tag.find_all('h3')[0])
                        data.append(tag.find_all('p')[0])
                        data.append(tag.find_all('p')[1])
                        data.append(tag.find_all('p')[2])
                        data.append(tag.find_all('p')[3])

                        # print("Passed value -  %s Reason: No need to scan, ignoring" % type(header).__str__)
                        break

                for (index, epi) in enumerate(index_list):
                    if index == len(index_list) - 1:
                        target = tag.contents[int(epi[0]):len(tag.contents)]
                    else:
                        target = tag.contents[int(epi[0]):int(index_list[index + 1][0])]
                    data += self.release(target)
            else:
                continue
        return data

    def release(self, tag):
        data = []
        self.decode_element(tag, data)
        return data

    def decode_element(self, tag, data_list):
        try:
            for content in tag.contents:
                if self.has_content(content):
                    self.decode_element(content, data_list)
                else:
                    data_list.append(content)
        except AttributeError:
            try:
                for e in tag:
                    if self.has_content(e):
                        self.decode_element(e, data_list)
                    else:
                        data_list.append(e)
            except IndexError as e2:
                print("ERERRRRRRRRRRRRRRRRRRE: %s", e2.__str__())

    def has_content(self, tag):
        try:
            e = tag.contents
            return True
        except AttributeError:
            return False

    def attribute(self):
        self.checkdb(True)
        icsa_map = {}
        max_page = 19
        for page in range(0, max_page + 1):
            url = ICSCERT_URL + "/advisories?page={n}".format(n=page)
            output = "advisories-{n}.html".format(n=page)
            print("downloading from {url}".format(url=url))
            util.downloadfrom(url, output, output_log=False)
            if os.path.exists(output):
                with open("advisories-{n}.html".format(n=page), encoding="UTF8") as fp:
                    soup = BeautifulSoup(fp, "html.parser")
                if soup is None:
                    raise cve.TypeInstanceException("The current file is not parameter instance of bs4")
                for element in soup.find_all("", {"class": "views-row"}):
                    icsa_id = element.find("", {"class": "views-field-field-docid-advisory-body"}).get_text()
                    title_part = element.find("", {"class": "views-field-title"})
                    title = title_part.get_text()
                    url = ICSCERT_URL + title_part.find('a')['href']
                    icsa_map[icsa_id] = (title, url)
            else:
                print('Failed load from url: {url}'.format(url=url))
        return icsa_map


if __name__ == "__main__":
    icscert = Icscert()
    print("Scraping ICS-CERT Advisories list...")
    data = icscert.attribute()
    print("Scraping done.")
    li = []
    for es in data.keys():
        try:
            esp = icscert.encap(icscert.scan(es[1:][:-1]))
        except Exception as e:
            print(e)

    """ 
    Export to dump file.
    with open("result.dump","w+",encoding="UTF8") as fp:
        for l in li:
            fp.write(l.__str__())
            fp.write('\n')
        fp.close()
    """

    """
    CVE-PATTERN
    
    CVE-[0-9]{3}-[0-9]{4}
    .+CVSS v([0-3]).+([0-9].[0-9]) has been calculated
    """

    """
    Vendor Name
    (.+) reports.+:
    The following 
    """


    """
    AFFECTED PRODUCTS
    <VendorName> reports ~~~~~~
    <products>
    <products2>
    ...
    IMPACT
    """